[{"id": "identity_2118", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConduct a diff-1 transform on a numeric frame column.\n\n        :returns: an H2OFrame where each element is equal to the corresponding element in the source\n            frame minus the previous-row element in the same frame."}]}, {"id": "identity_1845", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n\u0412\u044b\u0447\u0438\u0441\u043b\u0435\u043d\u0438\u0435 h-\u044d\u0432\u0440\u0438\u0441\u0442\u0438\u043a\u0438 \u0438\u0437 \u0440\u0430\u0431\u043e\u0442\u044b Hulden,2009 \u0434\u043b\u044f \u0442\u0435\u043a\u0443\u0449\u0435\u0439 \u0432\u0435\u0440\u0448\u0438\u043d\u044b \u0441\u043b\u043e\u0432\u0430\u0440\u044f\n\n        \u0410\u0440\u0433\u0443\u043c\u0435\u043d\u0442\u044b:\n        ----------\n        suffix : string\n            \u043d\u0435\u043f\u0440\u043e\u0447\u0438\u0442\u0430\u043d\u043d\u044b\u0439 \u0441\u0443\u0444\u0444\u0438\u043a\u0441 \u0432\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u0441\u043b\u043e\u0432\u0430\n        index : int\n            \u0438\u043d\u0434\u0435\u043a\u0441 \u0442\u0435\u043a\u0443\u0449\u0435\u0433\u043e \u0443\u0437\u043b\u0430 \u0432 \u0441\u043b\u043e\u0432\u0430\u0440\u0435\n\n        \u0412\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442:\n        -----------\n        cost : float\n            \u043e\u0446\u0435\u043d\u043a\u0430 \u0441\u043d\u0438\u0437\u0443 \u0434\u043b\u044f \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438 \u0437\u0430\u043c\u0435\u043d\u044b,\n            \u043f\u0440\u0438\u0432\u043e\u0434\u044f\u0449\u0435\u0439 \u043a \u0432\u0445\u043e\u0434\u043d\u043e\u043c\u0443 \u0441\u043b\u043e\u0432\u0443 \u0441 \u0441\u0443\u0444\u0444\u0438\u043a\u0441\u043e\u043c suffix,\n            \u0435\u0441\u043b\u0438 \u043f\u0440\u043e\u0447\u0438\u0442\u0430\u043d\u043d\u044b\u0439 \u043f\u0440\u0435\u0444\u0438\u043a\u0441 \u0441\u043b\u043e\u0432\u0430 \u0431\u0435\u0437 \u043e\u043f\u0435\u0447\u0430\u0442\u043a\u0438\n            \u043f\u0440\u0438\u0432\u0451\u043b \u0432 \u0432\u0435\u0440\u0448\u0438\u043d\u0443 \u0441 \u043d\u043e\u043c\u0435\u0440\u043e\u043c index"}]}, {"id": "identity_1812", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nVerifies if Amazon and additional certificates creates chain of trust to a root CA.\n\n    Args:\n        certs_chain: List of pycrypto X509 intermediate certificates from signature chain URL.\n        amazon_cert: Pycrypto X509 Amazon certificate.\n\n    Returns:\n        result: True if verification was successful, False if not."}]}, {"id": "identity_6904", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThe idea behind this method is to sort a list of domain hierarchicaly.\n\n        :param element: The element we are currently reading.\n        :type element: str\n\n        :return: The formatted element.\n        :rtype: str\n\n        .. note::\n            For a domain like :code:`aaa.bbb.ccc.tdl`.\n\n            A normal sorting is done in the following order:\n                1. :code:`aaa`\n                2. :code:`bbb`\n                3. :code:`ccc`\n                4. :code:`tdl`\n\n            This method allow the sorting to be done in the following order:\n                1. :code:`tdl`\n                2. :code:`ccc`\n                3. :code:`bbb`\n                4. :code:`aaa`"}]}, {"id": "identity_7421", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGets the information of the given Bot ID"}]}, {"id": "identity_6228", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\noutput option"}]}, {"id": "identity_5835", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nChecks calls to logging methods."}]}, {"id": "identity_8013", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBasic demo of the monitoring capabilities."}]}, {"id": "identity_6874", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUpdate the paths according to configs.\n\n        :param structure: The read structure.\n        :type structure: dict"}]}, {"id": "identity_2176", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConvert given number of bytes into a human readable representation, i.e. add prefix such as kb, Mb, Gb,\n    etc. The `size` argument must be a non-negative integer.\n\n    :param size: integer representing byte size of something\n    :return: string representation of the size, in human-readable form"}]}, {"id": "identity_5766", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\ngiven a dictionary representing an ordered graph (i.e. key are vertices\n    and values is a list of destination vertices representing edges), return a\n    list of detected cycles"}]}, {"id": "identity_8771", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nForgets about an entity (automatically called when an entity is\n        deleted). Call this to ensure that an entity that you've modified is\n        not automatically saved on ``session.commit()`` ."}]}, {"id": "identity_3218", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDrop columns (or a single column).\n\n        :param columns: List of columns or a single column name\n        :param inplace: {inplace}\n        :param check: When true, it will check if the column is used in virtual columns or the filter, and hide it instead."}]}, {"id": "identity_9557", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\non writeReqRecieved in monitor mode"}]}, {"id": "identity_9207", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nParameters:\n            x_t - 28x28 image\n            l_p - 2x1 focus vector\n        Returns:\n            7*14 matrix"}]}, {"id": "identity_5311", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the fixed part of the path without wildcard"}]}, {"id": "identity_317", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWe need to get the headers in addition to the body answer\n    to get the location from them\n    This function uses jenkins_request method from python-jenkins library\n    with just the return call changed\n\n    :param jenkins_server: The server to query\n    :param req: The request to execute\n    :return: Dict containing the response body (key body)\n        and the headers coming along (headers)"}]}, {"id": "identity_9692", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDoc on parent class :meth:`HdlStatement._iter_stms`"}]}, {"id": "identity_1893", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSimple tar archive extractor\n\n    Args:\n        file_path: path to the tar file to be extracted\n        extract_folder: folder to which the files will be extracted"}]}, {"id": "identity_7023", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn True if file is okay for modifying/recursing."}]}, {"id": "identity_2062", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a time column from individual components.\n\n        Each parameter should be either an integer, or a single-column H2OFrame\n        containing the corresponding time parts for each row.\n\n        The \"date\" part of the timestamp can be specified using either the tuple ``(year, month, day)``, or an\n        explicit ``date`` parameter. The \"time\" part of the timestamp is optional, but can be specified either via\n        the ``time`` parameter, or via the ``(hour, minute, second, msec)`` tuple.\n\n        :param year: the year part of the constructed date\n        :param month: the month part of the constructed date\n        :param day: the day-of-the-month part of the constructed date\n        :param hour: the hours part of the constructed date\n        :param minute: the minutes part of the constructed date\n        :param second: the seconds part of the constructed date\n        :param msec: the milliseconds part of the constructed date\n        :param date date: construct the timestamp from the Python's native ``datetime.date`` (or ``datetime.datetime``)\n            object. If the object passed is of type ``date``, then you can specify the time part using either the\n            ``time`` argument, or ``hour`` ... ``msec`` arguments (but not both). If the object passed is of type\n            ``datetime``, then no other arguments can be provided.\n        :param time time: construct the timestamp from this Python's native ``datetime.time`` object. This argument\n            cannot be used alone, it should be supplemented with either ``date`` argument, or ``year`` ... ``day``\n            tuple.\n\n        :returns: H2OFrame with one column containing the date constructed from the provided arguments."}]}, {"id": "identity_1921", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nIt is a implementation of the Luong et al. attention mechanism with general score and the constrained softmax (csoftmax).\n        Based on the papers:\n        https://arxiv.org/abs/1508.04025 \"Effective Approaches to Attention-based Neural Machine Translation\"\n        https://andre-martins.github.io/docs/emnlp2017_final.pdf \"Learning What's Easy: Fully Differentiable Neural Easy-First Taggers\"\n    Args:\n        hidden_for_sketch: A tensorflow tensor for a sketch computing. This tensor have dimensionality [None, max_num_tokens, sketch_hidden_size]\n        hidden_for_attn_alignment: A tensorflow tensor is aligned for output during a performing. This tensor have dimensionality [None, max_num_tokens, hidden_size_for_attn_alignment]\n        key: A tensorflow tensor with dimensionality [None, None, key_size]\n        attention_depth: Number of usage csoftmax\n    Returns:\n        final_aligned_hiddens: Tensor at the output with dimensionality [1, attention_depth, hidden_size_for_attn_alignment]"}]}, {"id": "identity_3166", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a pandas DataFrame containing the ndarray corresponding to the evaluated data\n\n         If index is given, that column is used for the index of the dataframe.\n\n         Example\n\n         >>> df_pandas = df.to_pandas_df([\"x\", \"y\", \"z\"])\n         >>> df_copy = vaex.from_pandas(df_pandas)\n\n        :param column_names: list of column names, to export, when None DataFrame.get_column_names(strings=strings, virtual=virtual) is used\n        :param selection: {selection}\n        :param strings: argument passed to DataFrame.get_column_names when column_names is None\n        :param virtual: argument passed to DataFrame.get_column_names when column_names is None\n        :param index_column: if this column is given it is used for the index of the DataFrame\n        :return: pandas.DataFrame object"}]}, {"id": "identity_3756", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSerialize the model into a Python dict of simple types.\n\n        Note that this method requires that the model is bound with\n        ``@bind_schema``."}]}, {"id": "identity_9384", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA list of tuples of the form [('n', AudioSegment), ('y', AudioSegment), etc.] is returned, where tuples\n        of the form ('n', AudioSegment) are the segments of sound where the event was not detected,\n        while ('y', AudioSegment) tuples were the segments of sound where the event was detected.\n\n        .. code-block:: python\n\n            # Example usage\n            import audiosegment\n            import keras\n            import keras.models\n            import numpy as np\n            import sys\n\n            class Model:\n                def __init__(self, modelpath):\n                    self.model = keras.models.load_model(modelpath)\n\n                def predict(self, seg):\n                    _bins, fft_vals = seg.fft()\n                    fft_vals = np.abs(fft_vals) / len(fft_vals)\n                    predicted_np_form = self.model.predict(np.array([fft_vals]), batch_size=1)\n                    prediction_as_int = int(round(predicted_np_form[0][0]))\n                    return prediction_as_int\n\n            modelpath = sys.argv[1]\n            wavpath = sys.argv[2]\n            model = Model(modelpath)\n            seg = audiosegment.from_file(wavpath).resample(sample_rate_Hz=32000, sample_width=2, channels=1)\n            pyes_to_no = 0.3  # The probability of one 30 ms sample being an event, and the next one not\n            pno_to_yes = 0.2  # The probability of one 30 ms sample not being an event, and the next one yes\n            ptrue_pos_rate = 0.8  # The true positive rate (probability of a predicted yes being right)\n            pfalse_neg_rate = 0.3  # The false negative rate (probability of a predicted no being wrong)\n            raw_prob = 0.7  # The raw probability of seeing the event in any random 30 ms slice of this file\n            events = seg.detect_event(model, ms_per_input=30, transition_matrix=[pyes_to_no, pno_to_yes],\n                                      model_stats=[ptrue_pos_rate, pfalse_neg_rate], event_length_s=0.25,\n                                      prob_raw_yes=raw_prob)\n            nos = [event[1] for event in events if event[0] == 'n']\n            yeses = [event[1] for event in events if event[0] == 'y']\n            if len(nos) > 1:\n                notdetected = nos[0].reduce(nos[1:])\n                notdetected.export(\"notdetected.wav\", format=\"WAV\")\n            if len(yeses) > 1:\n                detected = yeses[0].reduce(yeses[1:])\n                detected.export(\"detected.wav\", format=\"WAV\")\n\n\n        :param model:               The model. The model must have a predict() function which takes an AudioSegment\n                                    of `ms_per_input` number of ms and which outputs 1 if the audio event is detected\n                                    in that input, and 0 if not. Make sure to resample the AudioSegment to the right\n                                    values before calling this function on it.\n\n        :param ms_per_input:        The number of ms of AudioSegment to be fed into the model at a time. If this does not\n                                    come out even, the last AudioSegment will be zero-padded.\n\n        :param transition_matrix:   An iterable of the form: [p(yes->no), p(no->yes)]. That is, the probability of moving\n                                    from a 'yes' state to a 'no' state and the probability of vice versa.\n\n        :param model_stats:         An iterable of the form: [p(reality=1|output=1), p(reality=1|output=0)]. That is,\n                                    the probability of the ground truth really being a 1, given that the model output a 1,\n                                    and the probability of the ground truth being a 1, given that the model output a 0.\n\n        :param event_length_s:      The typical duration of the event you are looking for in seconds (can be a float).\n\n        :param start_as_yes:        If True, the first `ms_per_input` will be in the 'y' category. Otherwise it will be\n                                    in the 'n' category.\n\n        :param prob_raw_yes:        The raw probability of finding the event in any given `ms_per_input` vector.\n\n        :returns:                   A list of tuples of the form [('n', AudioSegment), ('y', AudioSegment), etc.],\n                                    where over the course of the list, the AudioSegment in tuple 3 picks up\n                                    where the one in tuple 2 left off.\n\n        :raises:                    ValueError if `ms_per_input` is negative or larger than the number of ms in this\n                                    AudioSegment; if `transition_matrix` or `model_stats` do not have a __len__ attribute\n                                    or are not length 2; if the values in `transition_matrix` or `model_stats` are not\n                                    in the closed interval [0.0, 1.0]."}]}, {"id": "identity_849", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nVGG 11-layer model (configuration \"A\") with batch normalization\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet"}]}, {"id": "identity_2204", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRetrieve the index in this metric's threshold list at which the given threshold is located.\n\n        If all are False (default), then return the training metric value.\n        If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n        \"valid\", and \"xval\".\n\n        :param float threshold: The threshold value to search for.\n        :param bool train: If train is True, then return the idx_by_threshold for the training data.\n        :param bool valid: If valid is True, then return the idx_by_threshold for the validation data.\n        :param bool xval:  If xval is True, then return the idx_by_threshold for the cross validation data.\n        :returns: The idx_by_threshold for this binomial model."}]}, {"id": "identity_7145", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRead the data encoding the DefaultsInformation structure and decode it\n        into its constituent parts.\n\n        Args:\n            input_buffer (stream): A data stream containing encoded object\n                data, supporting a read method; usually a BytearrayStream\n                object.\n            kmip_version (KMIPVersion): An enumeration defining the KMIP\n                version with which the object will be decoded. Optional,\n                defaults to KMIP 2.0.\n\n        Raises:\n            InvalidKmipEncoding: Raised if the object defaults are missing\n                from the encoding.\n            VersionNotSupported: Raised when a KMIP version is provided that\n                does not support the DefaultsInformation structure."}]}, {"id": "identity_247", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nEnsures that certain subfolders of AIRFLOW_HOME are on the classpath"}]}, {"id": "identity_6213", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nEfficient way to compute highly repetitive scoring\n    i.e. sequences are involved multiple time\n\n    Args:\n        sequences(list[str]): list of sequences (either hyp or ref)\n        scores_ids(list[tuple(int)]): list of pairs (hyp_id, ref_id)\n            ie. scores[i] = rouge_n(scores_ids[i][0],\n                                    scores_ids[i][1])\n\n    Returns:\n        scores: list of length `len(scores_ids)` containing rouge `n`\n                scores as a dict with 'f', 'r', 'p'\n    Raises:\n        KeyError: if there's a value of i in scores_ids that is not in\n                  [0, len(sequences)["}]}, {"id": "identity_5788", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet an indentation string for hanging indentation, consisting of the line-indent plus\n        a number of spaces to fill up to the column of this token.\n\n        e.g. the token indent for foo\n        in \"<TAB><TAB>print(foo)\"\n        is \"<TAB><TAB>      \""}]}, {"id": "identity_9676", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet constant name for value\n        name of constant is reused if same value was used before"}]}, {"id": "identity_4827", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRan when the configuration on a field changed."}]}, {"id": "identity_3229", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nJoin the columns of the other DataFrame to this one, assuming the ordering is the same"}]}, {"id": "identity_814", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nExecutes the sql and returns the first resulting row.\n\n        :param sql: the sql statement to be executed (str) or a list of\n            sql statements to execute\n        :type sql: str or list"}]}, {"id": "identity_7394", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreates encoder object for the given encoding.\n\n    :param encoding: desired output encoding protocol.\n    :type encoding: Encoding\n    :return: corresponding IEncoder object\n    :rtype: IEncoder"}]}, {"id": "identity_2823", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInstance depends on the API version:\n\n           * 2018-11-01: :class:`DdosCustomPoliciesOperations<azure.mgmt.network.v2018_11_01.operations.DdosCustomPoliciesOperations>`\n           * 2018-12-01: :class:`DdosCustomPoliciesOperations<azure.mgmt.network.v2018_12_01.operations.DdosCustomPoliciesOperations>`\n           * 2019-02-01: :class:`DdosCustomPoliciesOperations<azure.mgmt.network.v2019_02_01.operations.DdosCustomPoliciesOperations>`"}]}, {"id": "identity_8753", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nThis will execute the query, returning the key where a ZSET of your\n        results will be stored for pagination, further operations, etc.\n\n        The timeout must be a positive integer number of seconds for which to\n        set the expiration time on the key (this is to ensure that any cached\n        query results are eventually deleted, unless you make the explicit\n        step to use the PERSIST command).\n\n        .. note:: Limit clauses are ignored and not passed.\n\n        Usage::\n\n            ukey = User.query.endswith(email='@gmail.com').cached_result(30)\n            for i in xrange(0, conn.zcard(ukey), 100):\n                # refresh the expiration\n                conn.expire(ukey, 30)\n                users = User.get(conn.zrange(ukey, i, i+99))\n                ..."}]}, {"id": "identity_7231", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nBuild a name attribute, returned in a list for ease\n        of use in the caller"}]}, {"id": "identity_8716", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFind all vcard files inside this address book.\n\n        If a search string is given only files which contents match that will\n        be returned.\n\n        :param search: a regular expression to limit the results\n        :type search: str\n        :param search_in_source_files: apply search regexp directly on the .vcf files to speed up parsing (less accurate)\n        :type search_in_source_files: bool\n        :returns: the paths of the vcard files\n        :rtype: generator"}]}, {"id": "identity_7405", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAccepts a thrift annotation and converts it to a v1 annotation.\n\n        :param thrift_annotations: list of thrift annotations.\n        :type thrift_annotations: list of zipkin_core.Span.Annotation\n        :returns: (annotations, local_endpoint, kind)"}]}, {"id": "identity_3234", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nExports the DataFrame to a file written with arrow\n\n        :param DataFrameLocal df: DataFrame to export\n        :param str path: path for file\n        :param lis[str] column_names: list of column names to export or None for all columns\n        :param str byteorder: = for native, < for little endian and > for big endian (not supported for fits)\n        :param bool shuffle: export rows in random order\n        :param bool selection: export selection or not\n        :param progress: progress callback that gets a progress fraction as argument and should return True to continue,\n                or a default progress bar when progress=True\n        :param: bool virtual: When True, export virtual columns\n        :param str sort: expression used for sorting the output\n        :param bool ascending: sort ascending (True) or descending\n        :return:"}]}, {"id": "identity_1005", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nShrinks the input step size until the value and grad become finite."}]}, {"id": "identity_8050", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet file data for the given user_id, path, and query_fields.  The\n    query_fields parameter specifies which database fields should be\n    included in the returned file data."}]}, {"id": "identity_1967", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn function's declared arguments as a string.\n\n    For example for this function it returns \"func, highlight=None\"; for the ``_wrap`` function it returns\n    \"text, wrap_at=120, indent=4\". This should usually coincide with the function's declaration (the part\n    which is inside the parentheses)."}]}, {"id": "identity_1870", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReads input file in CONLL-U format\n\n    Args:\n        infile: a path to a file\n        word_column: column containing words (default=1)\n        pos_column: column containing part-of-speech labels (default=3)\n        tag_column: column containing fine-grained tags (default=5)\n        max_sents: maximal number of sents to read\n        read_only_words: whether to read only words\n\n    Returns:\n        a list of sentences. Each item contains a word sequence and a tag sequence, which is ``None``\n        in case ``read_only_words = True``"}]}, {"id": "identity_550", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nHelper method to get max partition of partitions with partition_key\n        from part specs. key:value pair in filter_map will be used to\n        filter out partitions.\n\n        :param part_specs: list of partition specs.\n        :type part_specs: list\n        :param partition_key: partition key name.\n        :type partition_key: str\n        :param filter_map: partition_key:partition_value map used for partition filtering,\n                           e.g. {'key1': 'value1', 'key2': 'value2'}.\n                           Only partitions matching all partition_key:partition_value\n                           pairs will be considered as candidates of max partition.\n        :type filter_map: map\n        :return: Max partition or None if part_specs is empty."}]}, {"id": "identity_3690", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nArgs:\n            passes (list[BasePass] or BasePass): pass(es) to be added to schedule\n            ignore_preserves (bool): ignore the preserves claim of passes. Default: False\n            ignore_requires (bool): ignore the requires need of passes. Default: False\n            max_iteration (int): max number of iterations of passes. Default: 1000\n            flow_controller_conditions (kwargs): See add_flow_controller(): Dictionary of\n            control flow plugins. Default:\n\n                * do_while (callable property_set -> boolean): The passes repeat until the\n                  callable returns False.\n                  Default: `lambda x: False # i.e. passes run once`\n\n                * condition (callable property_set -> boolean): The passes run only if the\n                  callable returns True.\n                  Default: `lambda x: True # i.e. passes run`\n\n        Raises:\n            TranspilerError: if a pass in passes is not a proper pass."}]}, {"id": "identity_9776", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSet volume level."}]}, {"id": "identity_5249", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDelete movies from a list that the user created.\n\n        A valid session id is required.\n\n        Args:\n            media_id: A movie id.\n\n        Returns:\n            A dict respresentation of the JSON returned from the API."}]}, {"id": "identity_133", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet a set of records from Presto"}]}, {"id": "identity_2657", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nList certificates in a specified key vault.\n\n        The GetCertificates operation returns the set of certificates resources\n        in the specified key vault. This operation requires the\n        certificates/list permission.\n\n        :param vault_base_url: The vault name, for example\n         https://myvault.vault.azure.net.\n        :type vault_base_url: str\n        :param maxresults: Maximum number of results to return in a page. If\n         not specified the service will return up to 25 results.\n        :type maxresults: int\n        :param include_pending: Specifies whether to include certificates\n         which are not completely provisioned.\n        :type include_pending: bool\n        :param dict custom_headers: headers that will be added to the request\n        :param bool raw: returns the direct response alongside the\n         deserialized response\n        :param operation_config: :ref:`Operation configuration\n         overrides<msrest:optionsforoperations>`.\n        :return: An iterator like instance of CertificateItem\n        :rtype:\n         ~azure.keyvault.v7_0.models.CertificateItemPaged[~azure.keyvault.v7_0.models.CertificateItem]\n        :raises:\n         :class:`KeyVaultErrorException<azure.keyvault.v7_0.models.KeyVaultErrorException>`"}]}, {"id": "identity_8468", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRemoves a logical interface from a device type.\n        Parameters:\n            - typeId (string) - the device type\n            - logicalInterfaceId (string) - the id returned by the platform on creation of the logical interface\n        Throws APIException on failure."}]}, {"id": "identity_2141", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPerform a REST API request to a previously connected server.\n\n    This function is mostly for internal purposes, but may occasionally be useful for direct access to\n    the backend H2O server. It has same parameters as :meth:`H2OConnection.request <h2o.backend.H2OConnection.request>`."}]}, {"id": "identity_4622", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCloses the client connection to the database."}]}, {"id": "identity_3007", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreates a key-function mapping.\n\n        The return value from the function should be either\n          - A tuple containing a name and stream\n          - A iterator of tuples containing a name and stream\n\n        Any extra arguments will be passed to the function."}]}, {"id": "identity_6431", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns memory overhead."}]}, {"id": "identity_4882", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInit client"}]}, {"id": "identity_1989", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nNormal node shutdown.\n        Ignore failures for now.\n\n        :return none"}]}, {"id": "identity_6618", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConverts one or more parsed aggregate reports to flat CSV format, including\n    headers\n\n    Args:\n        reports: A parsed aggregate report or list of parsed aggregate reports\n\n    Returns:\n        str: Parsed aggregate report data in flat CSV format, including headers"}]}, {"id": "identity_5009", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nParse a mbox file.\n\n        This method parses a mbox file and returns an iterator of dictionaries.\n        Each one of this contains an email message.\n\n        :param filepath: path of the mbox to parse\n\n        :returns : generator of messages; each message is stored in a\n            dictionary of type `requests.structures.CaseInsensitiveDict`"}]}, {"id": "identity_3789", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn quaternion for rotation about given axis.\n\n    Args:\n        angle (float): Angle in radians.\n        axis (str): Axis for rotation\n\n    Returns:\n        Quaternion: Quaternion for axis rotation.\n\n    Raises:\n        ValueError: Invalid input axis."}]}, {"id": "identity_2123", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMake a vector of the positions of (first) matches of its first argument in its second.\n\n        Only applicable to single-column categorical/string frames.\n\n        :param List table: the list of items to match against\n        :param int nomatch: value that should be returned when there is no match.\n        :returns: a new H2OFrame containing for each cell from the source frame the index where\n            the pattern ``table`` first occurs within that cell."}]}, {"id": "identity_2067", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nChange names of columns in the frame.\n\n        Dict key is an index or name of the column whose name is to be set.\n        Dict value is the new name of the column.\n\n        :param columns: dict-like transformations to apply to the column names"}]}, {"id": "identity_4602", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the failing step's data that happened during this solid's execution, if any"}]}, {"id": "identity_7508", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n**Description**\n            Create a new policy\n\n        **Arguments**\n            - name: The name of the policy.\n            - rules: A list of Anchore PolicyRule elements (while creating/updating a policy, new rule IDs will be created backend side)\n            - comment: A human-readable description.\n            - bundleid: Target bundle. If not specified, the currently active bundle will be used.\n\n        **Success Return Value**\n            A JSON object containing the policy description."}]}, {"id": "identity_368", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRetrieves connection to Google Compute Engine.\n\n        :return: Google Compute Engine services object\n        :rtype: dict"}]}, {"id": "identity_9107", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAdd an item to the current basket.\n\n        :param Item item: Item from menu.\n        :param int variant: Item SKU id. Ignored if the item is a side.\n        :param int quantity: The quantity of item to be added.\n        :return: A response having added an item to the current basket.\n        :rtype: requests.Response"}]}, {"id": "identity_9793", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreates a piece instance from a piece symbol.\n        Raises `ValueError` if the symbol is invalid."}]}, {"id": "identity_707", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet results (or just s3 locations) of a command from Qubole and save into a file\n        :param ti: Task Instance of the dag, used to determine the Quboles command id\n        :param fp: Optional file pointer, will create one and return if None passed\n        :param inline: True to download actual results, False to get s3 locations only\n        :param delim: Replaces the CTL-A chars with the given delim, defaults to ','\n        :param fetch: when inline is True, get results directly from s3 (if large)\n        :return: file location containing actual results or s3 locations of results"}]}, {"id": "identity_4083", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nEmbed default qubit LO frequencies from backend and format them to list object.\n        If configured lo frequency is the same as default, this method returns `None`.\n\n        Args:\n            user_lo_config (LoConfig): A dictionary of LOs to format.\n\n        Returns:\n            list: A list of qubit LOs.\n\n        Raises:\n            PulseError: when LO frequencies are missing."}]}, {"id": "identity_7086", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA utility function that creates a list of enumeration values from a bit\n    mask for a specific mask enumeration class.\n\n    Args:\n        enumeration (class): The enumeration class from which to draw\n            enumeration values.\n        mask (int): The bit mask from which to identify enumeration values.\n\n    Returns:\n        list: A list of enumeration values corresponding to the bit mask."}]}, {"id": "identity_345", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns a command that can be executed anywhere where airflow is\n        installed. This command is part of the message sent to executors by\n        the orchestrator."}]}, {"id": "identity_3737", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nProcess a custom unitary node."}]}, {"id": "identity_1927", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nIt is a implementation of the Bahdanau et al. attention mechanism. Based on the paper:\n        https://arxiv.org/abs/1409.0473 \"Neural Machine Translation by Jointly Learning to Align and Translate\"\n    Args:\n        key: A tensorflow tensor with dimensionality [None, None, key_size]\n        context: A tensorflow tensor with dimensionality [None, None, max_num_tokens, token_size]\n        hidden_size: Number of units in hidden representation\n        projected_align: Using dense layer for hidden representation of context.\n        If true, between input and attention mechanism insert a dense layer with dimensionality [hidden_size].\n        If false, a dense layer is not used.\n    Returns:\n        output: Tensor at the output with dimensionality [None, None, hidden_size]"}]}, {"id": "identity_9029", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nHandle command line arguments to convert a file to a JSON stream as a\n    script."}]}, {"id": "identity_7494", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n**Description**\n            Creates an empty dashboard. You can then add panels by using ``add_dashboard_panel``.\n\n        **Arguments**\n            - **name**: the name of the dashboard that will be created.\n\n        **Success Return Value**\n            A dictionary showing the details of the new dashboard.\n\n        **Example**\n            `examples/dashboard.py <https://github.com/draios/python-sdc-client/blob/master/examples/dashboard.py>`_"}]}, {"id": "identity_1052", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n`high - low`."}]}, {"id": "identity_5136", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFetch the pages\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items"}]}, {"id": "identity_5895", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCalled for function and method definitions (def).\n\n        :param node: Node for a function or method definition in the AST\n        :type node: :class:`astroid.scoped_nodes.Function`"}]}, {"id": "identity_3743", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a DAG node out of a parsed AST op node.\n\n        Args:\n            name (str): operation name to apply to the dag.\n            params (list): op parameters\n            qargs (list(QuantumRegister, int)): qubits to attach to\n\n        Raises:\n            QiskitError: if encountering a non-basis opaque gate"}]}, {"id": "identity_1107", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCompute the marginal of this GP over function values at `index_points`.\n\n    Args:\n      index_points: `float` `Tensor` representing finite (batch of) vector(s) of\n        points in the index set over which the GP is defined. Shape has the form\n        `[b1, ..., bB, e, f1, ..., fF]` where `F` is the number of feature\n        dimensions and must equal `kernel.feature_ndims` and `e` is the number\n        (size) of index points in each batch. Ultimately this distribution\n        corresponds to a `e`-dimensional multivariate normal. The batch shape\n        must be broadcastable with `kernel.batch_shape` and any batch dims\n        yielded by `mean_fn`.\n\n    Returns:\n      marginal: a `Normal` or `MultivariateNormalLinearOperator` distribution,\n        according to whether `index_points` consists of one or many index\n        points, respectively."}]}, {"id": "identity_2594", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDeletes the specified VM Image from the image repository that is\n        associated with the specified subscription.\n\n        vm_image_name:\n            The name of the image.\n        delete_vhd:\n            Deletes the underlying vhd blob in Azure storage."}]}, {"id": "identity_25", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nstr->dict\n    Information for CKPlayer API content."}]}, {"id": "identity_3153", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSets the internal state of the df\n\n        Example:\n\n        >>> import vaex\n        >>> df = vaex.from_scalars(x=1, y=2)\n        >>> df\n          #    x    y        r\n          0    1    2  2.23607\n        >>> df['r'] = (df.x**2 + df.y**2)**0.5\n        >>> state = df.state_get()\n        >>> state\n        {'active_range': [0, 1],\n        'column_names': ['x', 'y', 'r'],\n        'description': None,\n        'descriptions': {},\n        'functions': {},\n        'renamed_columns': [],\n        'selections': {'__filter__': None},\n        'ucds': {},\n        'units': {},\n        'variables': {},\n        'virtual_columns': {'r': '(((x ** 2) + (y ** 2)) ** 0.5)'}}\n        >>> df2 = vaex.from_scalars(x=3, y=4)\n        >>> df2.state_set(state)  # now the virtual functions are 'copied'\n        >>> df2\n          #    x    y    r\n          0    3    4    5\n\n        :param state: dict as returned by :meth:`DataFrame.state_get`.\n        :param bool use_active_range: Whether to use the active range or not."}]}, {"id": "identity_765", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the task runner that can be used to run the given job.\n\n    :param local_task_job: The LocalTaskJob associated with the TaskInstance\n        that needs to be executed.\n    :type local_task_job: airflow.jobs.LocalTaskJob\n    :return: The task runner to use to run the task.\n    :rtype: airflow.task.task_runner.base_task_runner.BaseTaskRunner"}]}, {"id": "identity_7156", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nStop the server.\n\n        Halt server client connections and clean up any existing connection\n        threads.\n\n        Raises:\n            NetworkingError: Raised if a failure occurs while sutting down\n                or closing the TLS server socket."}]}, {"id": "identity_7648", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nJupyter Notebook magic repr function as a row \u2013\u00a0used by\n        ``Legend._repr_html_()``."}]}, {"id": "identity_9852", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck if value has id attribute and return it.\n\n        :param value: The value to get id from.\n        :return: The value.id."}]}, {"id": "identity_2706", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMerges two `Reservation`s.\n\n        Merge the specified `Reservation`s into a new `Reservation`. The two\n        `Reservation`s being merged must have same properties.\n\n        :param reservation_order_id: Order Id of the reservation\n        :type reservation_order_id: str\n        :param sources: Format of the resource id should be\n         /providers/Microsoft.Capacity/reservationOrders/{reservationOrderId}/reservations/{reservationId}\n        :type sources: list[str]\n        :param dict custom_headers: headers that will be added to the request\n        :param bool raw: The poller return type is ClientRawResponse, the\n         direct response alongside the deserialized response\n        :param polling: True for ARMPolling, False for no polling, or a\n         polling object for personal polling strategy\n        :return: An instance of LROPoller that returns list or\n         ClientRawResponse<list> if raw==True\n        :rtype:\n         ~msrestazure.azure_operation.AzureOperationPoller[list[~azure.mgmt.reservations.models.ReservationResponse]]\n         or\n         ~msrestazure.azure_operation.AzureOperationPoller[~msrest.pipeline.ClientRawResponse[list[~azure.mgmt.reservations.models.ReservationResponse]]]\n        :raises:\n         :class:`ErrorException<azure.mgmt.reservations.models.ErrorException>`"}]}, {"id": "identity_3411", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nMel-frequency cepstral coefficients (MFCCs)\n\n    Parameters\n    ----------\n    y : np.ndarray [shape=(n,)] or None\n        audio time series\n\n    sr : number > 0 [scalar]\n        sampling rate of `y`\n\n    S : np.ndarray [shape=(d, t)] or None\n        log-power Mel spectrogram\n\n    n_mfcc: int > 0 [scalar]\n        number of MFCCs to return\n\n    dct_type : None, or {1, 2, 3}\n        Discrete cosine transform (DCT) type.\n        By default, DCT type-2 is used.\n\n    norm : None or 'ortho'\n        If `dct_type` is `2 or 3`, setting `norm='ortho'` uses an ortho-normal\n        DCT basis.\n\n        Normalization is not supported for `dct_type=1`.\n\n    kwargs : additional keyword arguments\n        Arguments to `melspectrogram`, if operating\n        on time series input\n\n    Returns\n    -------\n    M : np.ndarray [shape=(n_mfcc, t)]\n        MFCC sequence\n\n    See Also\n    --------\n    melspectrogram\n    scipy.fftpack.dct\n\n    Examples\n    --------\n    Generate mfccs from a time series\n\n    >>> y, sr = librosa.load(librosa.util.example_audio_file(), offset=30, duration=5)\n    >>> librosa.feature.mfcc(y=y, sr=sr)\n    array([[ -5.229e+02,  -4.944e+02, ...,  -5.229e+02,  -5.229e+02],\n           [  7.105e-15,   3.787e+01, ...,  -7.105e-15,  -7.105e-15],\n           ...,\n           [  1.066e-14,  -7.500e+00, ...,   1.421e-14,   1.421e-14],\n           [  3.109e-14,  -5.058e+00, ...,   2.931e-14,   2.931e-14]])\n\n    Use a pre-computed log-power Mel spectrogram\n\n    >>> S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128,\n    ...                                    fmax=8000)\n    >>> librosa.feature.mfcc(S=librosa.power_to_db(S))\n    array([[ -5.207e+02,  -4.898e+02, ...,  -5.207e+02,  -5.207e+02],\n           [ -2.576e-14,   4.054e+01, ...,  -3.997e-14,  -3.997e-14],\n           ...,\n           [  7.105e-15,  -3.534e+00, ...,   0.000e+00,   0.000e+00],\n           [  3.020e-14,  -2.613e+00, ...,   3.553e-14,   3.553e-14]])\n\n    Get more components\n\n    >>> mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n\n    Visualize the MFCC series\n\n    >>> import matplotlib.pyplot as plt\n    >>> plt.figure(figsize=(10, 4))\n    >>> librosa.display.specshow(mfccs, x_axis='time')\n    >>> plt.colorbar()\n    >>> plt.title('MFCC')\n    >>> plt.tight_layout()\n\n    Compare different DCT bases\n\n    >>> m_slaney = librosa.feature.mfcc(y=y, sr=sr, dct_type=2)\n    >>> m_htk = librosa.feature.mfcc(y=y, sr=sr, dct_type=3)\n    >>> plt.figure(figsize=(10, 6))\n    >>> plt.subplot(2, 1, 1)\n    >>> librosa.display.specshow(m_slaney, x_axis='time')\n    >>> plt.title('RASTAMAT / Auditory toolbox (dct_type=2)')\n    >>> plt.colorbar()\n    >>> plt.subplot(2, 1, 2)\n    >>> librosa.display.specshow(m_htk, x_axis='time')\n    >>> plt.title('HTK-style (dct_type=3)')\n    >>> plt.colorbar()\n    >>> plt.tight_layout()"}]}, {"id": "identity_9572", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nwrite data to interface"}]}, {"id": "identity_9628", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConstruct value from pythonic value (int, bytes, enum.Enum member)"}]}, {"id": "identity_2519", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n:param vault: The vault uri.\n        :type vault: str\n        :param name: The key name.\n        :type name: str\n        :param version: The key version.\n        :type version: str\n        :rtype: KeyVaultId"}]}, {"id": "identity_1105", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRuns HMC on the text-messages unnormalized posterior."}]}, {"id": "identity_5395", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the current request object. Implementation varies on\n    library support. Modified below when we know which framework\n    is being used."}]}, {"id": "identity_514", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreates a new ACL entry on the specified object.\n        See: https://cloud.google.com/storage/docs/json_api/v1/objectAccessControls/insert\n\n        :param bucket_name: Name of a bucket_name.\n        :type bucket_name: str\n        :param object_name: Name of the object. For information about how to URL encode\n            object names to be path safe, see:\n            https://cloud.google.com/storage/docs/json_api/#encoding\n        :type object_name: str\n        :param entity: The entity holding the permission, in one of the following forms:\n            user-userId, user-email, group-groupId, group-email, domain-domain,\n            project-team-projectId, allUsers, allAuthenticatedUsers\n            See: https://cloud.google.com/storage/docs/access-control/lists#scopes\n        :type entity: str\n        :param role: The access permission for the entity.\n            Acceptable values are: \"OWNER\", \"READER\".\n        :type role: str\n        :param user_project: (Optional) The project to be billed for this request.\n            Required for Requester Pays buckets.\n        :type user_project: str"}]}, {"id": "identity_4556", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nEnsures argument obj is a dictionary, and enforces that the keys/values conform to the types\n    specified by key_type, value_type."}]}, {"id": "identity_1127", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDecompose a forecast distribution into contributions from each component.\n\n  Args:\n    model: An instance of `tfp.sts.Sum` representing a structural time series\n      model.\n    forecast_dist: A `Distribution` instance returned by `tfp.sts.forecast()`.\n      (specifically, must be a `tfd.MixtureSameFamily` over a\n      `tfd.LinearGaussianStateSpaceModel` parameterized by posterior samples).\n    parameter_samples: Python `list` of `Tensors` representing posterior samples\n      of model parameters, with shapes `[concat([[num_posterior_draws],\n      param.prior.batch_shape, param.prior.event_shape]) for param in\n      model.parameters]`. This may optionally also be a map (Python `dict`) of\n      parameter names to `Tensor` values.\n  Returns:\n    component_forecasts: A `collections.OrderedDict` instance mapping\n      component StructuralTimeSeries instances (elements of `model.components`)\n      to `tfd.Distribution` instances representing the marginal forecast for\n      each component. Each distribution has batch and event shape matching\n      `forecast_dist` (specifically, the event shape is\n      `[num_steps_forecast]`).\n\n  #### Examples\n\n  Suppose we've built a model, fit it to data, and constructed a forecast\n  distribution:\n\n  ```python\n    day_of_week = tfp.sts.Seasonal(\n        num_seasons=7,\n        observed_time_series=observed_time_series,\n        name='day_of_week')\n    local_linear_trend = tfp.sts.LocalLinearTrend(\n        observed_time_series=observed_time_series,\n        name='local_linear_trend')\n    model = tfp.sts.Sum(components=[day_of_week, local_linear_trend],\n                        observed_time_series=observed_time_series)\n\n    num_steps_forecast = 50\n    samples, kernel_results = tfp.sts.fit_with_hmc(model, observed_time_series)\n    forecast_dist = tfp.sts.forecast(model, observed_time_series,\n                                 parameter_samples=samples,\n                                 num_steps_forecast=num_steps_forecast)\n  ```\n\n  To extract the forecast for individual components, pass the forecast\n  distribution into `decompose_forecast_by_components`:\n\n  ```python\n    component_forecasts = decompose_forecast_by_component(\n      model, forecast_dist, samples)\n\n    # Component mean and stddev have shape `[num_steps_forecast]`.\n    day_of_week_effect_mean = forecast_components[day_of_week].mean()\n    day_of_week_effect_stddev = forecast_components[day_of_week].stddev()\n  ```\n\n  Using the component forecasts, we can visualize the uncertainty for each\n  component:\n\n  ```\n  from matplotlib import pylab as plt\n  num_components = len(component_forecasts)\n  xs = np.arange(num_steps_forecast)\n  fig = plt.figure(figsize=(12, 3 * num_components))\n  for i, (component, component_dist) in enumerate(component_forecasts.items()):\n\n    # If in graph mode, replace `.numpy()` with `.eval()` or `sess.run()`.\n    component_mean = component_dist.mean().numpy()\n    component_stddev = component_dist.stddev().numpy()\n\n    ax = fig.add_subplot(num_components, 1, 1 + i)\n    ax.plot(xs, component_mean, lw=2)\n    ax.fill_between(xs,\n                    component_mean - 2 * component_stddev,\n                    component_mean + 2 * component_stddev,\n                    alpha=0.5)\n    ax.set_title(component.name)\n  ```"}]}, {"id": "identity_5529", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nvisit an astroid.Import node\n\n        resolve module dependencies"}]}, {"id": "identity_9224", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA utility function of concatenate."}]}, {"id": "identity_794", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFAB leaves faulty permissions that need to be cleaned up"}]}, {"id": "identity_8899", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn True if we are looking at a def statement"}]}, {"id": "identity_2274", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDictionary of actual parameters of the model."}]}, {"id": "identity_5307", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet a temp filename for atomic download."}]}, {"id": "identity_5476", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nbuild the internal or the external depedency graph"}]}, {"id": "identity_138", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nChecks if a collection exists in CosmosDB."}]}, {"id": "identity_9484", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nNaive neighborhoods algo."}]}, {"id": "identity_8849", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nScript interface to read a command. `prompt' is a parameter for\n        compatibilty and is ignored."}]}, {"id": "identity_5392", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPatches the pyramid_debugtoolbar (if installed) to display a link to the related rollbar item."}]}, {"id": "identity_4912", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn the items from GitLab API using links pagination"}]}, {"id": "identity_4278", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\ngate_op : id '(' ')' id_list ';'"}]}, {"id": "identity_7468", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n**Description**\n            Removes a panel from the dashboard. The panel to remove is identified by the specified ``name``.\n\n        **Arguments**\n            - **name**: name of the panel to find and remove\n\n        **Success Return Value**\n            A dictionary showing the details of the edited dashboard.\n\n        **Example**\n            `examples/dashboard.py <https://github.com/draios/python-sdc-client/blob/master/examples/dashboard.py>`_"}]}, {"id": "identity_568", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFor the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionReferenceImageCreateOperator`"}]}, {"id": "identity_1263", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nShrinks the simplex around the best vertex."}]}, {"id": "identity_8749", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWhen provided with keyword arguments of the form ``col=pattern``, this\n        will limit the entities returned to those that include the provided\n        pattern. Note that 'like' queries require that the ``prefix=True``\n        option must have been provided as part of the column definition.\n\n        Patterns allow for 4 wildcard characters, whose semantics are as\n        follows:\n\n            * *?* - will match 0 or 1 of any character\n            * *\\** - will match 0 or more of any character\n            * *+* - will match 1 or more of any character\n            * *!* - will match exactly 1 of any character\n\n        As an example, imagine that you have enabled the required prefix\n        matching on your ``User.email`` column. And lets say that you want to\n        find everyone with an email address that contains the name 'frank'\n        before the ``@`` sign. You can use either of the following patterns\n        to discover those users.\n\n            * *\\*frank\\*@*\n            * *\\*frank\\*@*\n\n        .. note:: Like queries implicitly start at the beginning of strings\n          checked, so if you want to match a pattern that doesn't start at\n          the beginning of a string, you should prefix it with one of the\n          wildcard characters (like ``*`` as we did with the 'frank' pattern)."}]}, {"id": "identity_1684", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSet the running variance of the layer.\n        Only use this method for a BatchNormalization layer.\n        :param running_std: a Numpy array."}]}, {"id": "identity_4038", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nApply RZZ to circuit."}]}, {"id": "identity_7954", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the scaled z positions of the points as doubles"}]}, {"id": "identity_4573", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSnowflake configuration.\n\n    See the Snowflake documentation for reference:\n        https://docs.snowflake.net/manuals/user-guide/python-connector-api.html"}]}, {"id": "identity_4905", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet the merge versions from pagination"}]}, {"id": "identity_177", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLaunch DagFileProcessorManager processor and start DAG parsing loop in manager."}]}, {"id": "identity_9042", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWhen sent in an authorized REST request, only strings and integers can be\n    transmitted accurately. Other types of data need to be encoded into JSON."}]}, {"id": "identity_9766", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConvert all ternary operators to IfContainers"}]}, {"id": "identity_4330", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUnmajority gate."}]}, {"id": "identity_7465", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\n**Description**\n            Changes the grouping hierarchy in the Explore panel of the current user.\n\n        **Arguments**\n            - **new_hierarchy**: a list of sysdig segmentation metrics indicating the new grouping hierarchy."}]}, {"id": "identity_4735", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nHandle a GET request.\n\n        property_name -- the name of the property from the URL path"}]}, {"id": "identity_7174", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInstantiates an RSA key from bytes.\n\n        Args:\n            bytes (byte string): Bytes of RSA private key.\n        Returns:\n            private_key\n                (cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateKey):\n                RSA private key created from key bytes."}]}, {"id": "identity_8665", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPrepare the search query string from the given command line args.\n\n    Each address book can get a search query string to filter vcards befor\n    loading them.  Depending on the question if the address book is used for\n    source or target searches different regexes have to be combined into one\n    search string.\n\n    :param args: the parsed command line\n    :type args: argparse.Namespace\n    :returns: a dict mapping abook names to their loading queries, if the query\n        is None it means that all cards should be loaded\n    :rtype: dict(str:str or None)"}]}, {"id": "identity_284", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLaunches the pod synchronously and waits for completion.\n        Args:\n            pod (Pod):\n            startup_timeout (int): Timeout for startup of the pod (if pod is pending for\n             too long, considers task a failure"}]}, {"id": "identity_9876", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLoads all symbol maps from db"}]}, {"id": "identity_9296", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLoad parameters to the block."}]}, {"id": "identity_5792", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nExtracts indentation information for a continued indent."}]}, {"id": "identity_931", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the config of this layer.\n\n    This Layer's `make_distribution_fn` is serialized via a library built on\n    Python pickle.  This serialization of Python functions is provided for\n    convenience, but:\n\n      1. The use of this format for long-term storage of models is discouraged.\n         In particular, it may not be possible to deserialize in a different\n         version of Python.\n\n      2. While serialization is generally supported for lambdas, local\n         functions, and static methods (and closures over these constructs),\n         complex functions may fail to serialize.\n\n      3. `Tensor` objects (and functions referencing `Tensor` objects) can only\n         be serialized when the tensor value is statically known.  (Such Tensors\n         are serialized as numpy arrays.)\n\n    Instead of relying on `DistributionLambda.get_config`, consider subclassing\n    `DistributionLambda` and directly implementing Keras serialization via\n    `get_config` / `from_config`.\n\n    NOTE: At the moment, `DistributionLambda` can only be serialized if the\n    `convert_to_tensor_fn` is a serializable Keras object (i.e., implements\n    `get_config`) or one of the standard values:\n     - `Distribution.sample` (or `\"sample\"`)\n     - `Distribution.mean` (or `\"mean\"`)\n     - `Distribution.mode` (or `\"mode\"`)\n     - `Distribution.stddev` (or `\"stddev\"`)\n     - `Distribution.variance` (or `\"variance\"`)"}]}, {"id": "identity_7551", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAbsorb trits into the sponge.\n\n        :param trits:\n            Sequence of trits to absorb.\n\n        :param offset:\n            Starting offset in ``trits``.\n\n        :param length:\n            Number of trits to absorb.  Defaults to ``len(trits)``."}]}, {"id": "identity_2371", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn the list of H\u2082O schemas.\n\n    :param raw: if True, then the complete response to .../schemas is returned (including the metadata)"}]}, {"id": "identity_7684", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTurn a 1D array into a striplog, given a cutoff.\n\n        Args:\n            log (array-like): A 1D array or a list of integers.\n            cutoff (number or array-like): The log value(s) at which to bin\n                the log. Optional.\n            components (array-like): A list of components. Use this or\n                ``legend``.\n            legend (``Legend``): A legend object. Use this or ``components``.\n            legend_field ('str'): If you're not trying to match against\n                components, then you can match the log values to this field in\n                the Decors.\n            field (str): The field in the Interval's ``data`` to store the log\n                values as.\n            right (bool): Which side of the cutoff to send things that are\n                equal to, i.e. right on, the cutoff.\n            basis (array-like): A depth basis for the log, so striplog knows\n                where to put the boundaries.\n            source (str): The source of the data. Default 'Log'.\n\n        Returns:\n            Striplog: The ``striplog`` object."}]}, {"id": "identity_5039", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFetch the tweets from the server.\n\n        This method fetches tweets from the TwitterSearch API published in the last seven days.\n\n        :param category: the category of items to fetch\n        :param since_id: if not null, it returns results with an ID greater than the specified ID\n        :param max_id: when it is set or if not None, it returns results with an ID less than the specified ID\n        :param geocode: if enabled, returns tweets by users located at latitude,longitude,\"mi\"|\"km\"\n        :param lang: if enabled, restricts tweets to the given language, given by an ISO 639-1 code\n        :param include_entities: if disabled, it excludes entities node\n        :param tweets_type: type of tweets returned. Default is \u201cmixed\u201d, others are \"recent\" and \"popular\"\n\n        :returns: a generator of tweets"}]}, {"id": "identity_3077", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a graphviz.Digraph object with a graph of the expression"}]}, {"id": "identity_3801", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTest if an array is a diagonal matrix"}]}, {"id": "identity_7239", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFind a group of entry points with unique names.\n\n    Returns a dictionary of names to :class:`EntryPoint` objects."}]}, {"id": "identity_7104", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRead the data encoding the Create request payload and decode it into\n        its constituent parts.\n\n        Args:\n            input_buffer (stream): A data buffer containing encoded object\n                data, supporting a read method.\n            kmip_version (KMIPVersion): An enumeration defining the KMIP\n                version with which the object will be decoded. Optional,\n                defaults to KMIP 1.0.\n\n        Raises:\n            InvalidKmipEncoding: Raised if the object type or template\n                attribute is missing from the encoded payload."}]}, {"id": "identity_2851", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet a site's publish profile as an object\n\n        webspace_name:\n            The name of the webspace.\n        website_name:\n            The name of the website."}]}, {"id": "identity_4243", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn converted `Snapshot`.\n\n        Args:\n            shift(int): Offset time.\n            instruction (Snapshot): snapshot instruction.\n        Returns:\n            dict: Dictionary of required parameters."}]}, {"id": "identity_7698", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFor backwards compatibility."}]}, {"id": "identity_4078", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSubmit the job to the backend for execution.\n\n        Raises:\n            QobjValidationError: if the JSON serialization of the Qobj passed\n            during construction does not validate against the Qobj schema.\n\n            JobError: if trying to re-submit the job."}]}, {"id": "identity_7246", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGenerate action."}]}, {"id": "identity_7902", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn a list of templates as template objects."}]}, {"id": "identity_571", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFor the documentation see:\n        :py:class:`~airflow.contrib.operators.gcp_vision_operator.CloudVisionDetectImageSafeSearchOperator`"}]}, {"id": "identity_9130", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConvert string column into datetime column\n\n    ---\n\n    ### Parameters\n\n    *mandatory :*\n    - `column` (*str*): name of the column to format\n    - `format` (*str*): current format of the values (see [available formats](\n    https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior))"}]}, {"id": "identity_845", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nA list of states indicating that a task either has not completed\n        a run or has not even started."}]}, {"id": "identity_74", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the state of a DagRun at the command line.\n    >>> airflow dag_state tutorial 2015-01-01T00:00:00.000000\n    running"}]}, {"id": "identity_6206", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPages through an object collection from the bitbucket API.\n        Returns an iterator that lazily goes through all the 'values'\n        of all the pages in the collection."}]}, {"id": "identity_5925", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRequest token handler decorator.\n\n        The decorated function should return an dictionary or None as\n        the extra credentials for creating the token response.\n\n        If you don't need to add any extra credentials, it could be as\n        simple as::\n\n            @app.route('/oauth/request_token')\n            @oauth.request_token_handler\n            def request_token():\n                return {}"}]}, {"id": "identity_6291", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCreate a cylinder or cone primitive. Usage is based on OpenSCAD.\n    # height = height of the cylinder\n    # radius1 = radius of the cone on bottom end\n    # radius2 = radius of the cone on top end\n    # center = If true will center the height of the cone/cylinder around\n    # the origin. Default is false, placing the base of the cylinder or radius1\n    # radius of cone at the origin.\n    #\n    cir_segments Number of sides of the polygonal approximation of the cone\n\n    color = specify a color name to apply vertex colors to the newly\n    # created mesh"}]}, {"id": "identity_3083", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nOpen a DataFrame from file given by path.\n\n    Example:\n\n    >>> ds = vaex.open('sometable.hdf5')\n    >>> ds = vaex.open('somedata*.csv', convert='bigdata.hdf5')\n\n    :param str path: local or absolute path to file, or glob string\n    :param convert: convert files to an hdf5 file for optimization, can also be a path\n    :param bool shuffle: shuffle converted DataFrame or not\n    :param args: extra arguments for file readers that need it\n    :param kwargs: extra keyword arguments\n    :param bool copy_index: copy index when source is read via pandas\n    :return: return a DataFrame on succes, otherwise None\n    :rtype: DataFrame"}]}, {"id": "identity_8780", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSaves the current entity to Redis. Will only save changed data by\n        default, but you can force a full save by passing ``full=True``.\n\n        If the underlying entity was deleted and you want to re-save the entity,\n        you can pass ``force=True`` to force a full re-save of the entity."}]}, {"id": "identity_9227", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRMSPROP optimization core."}]}, {"id": "identity_4234", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nr'\\n+"}]}, {"id": "identity_4112", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGenerates triangle wave `SamplePulse`.\n\n    Applies `left` sampling strategy to generate discrete pulse from continuous function.\n\n    Args:\n        duration: Duration of pulse. Must be greater than zero.\n        amp: Pulse amplitude. Wave range is [-amp, amp].\n        period: Pulse period, units of dt. If `None` defaults to single cycle.\n        phase: Pulse phase.\n        name: Name of pulse."}]}, {"id": "identity_5079", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCheck all API tokens defined and choose one with most remaining API points"}]}, {"id": "identity_8260", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUpdate the HTTP headers used for requests in this session.\n\n        Note: Updates provided by the dictionary passed as the `headers`\n        parameter to this method are merged into the session headers by adding\n        new key-value pairs and/or updating the values of existing keys. The\n        session headers are not replaced by the provided dictionary.\n\n        Args:\n             headers(dict): Updates to the current session headers."}]}, {"id": "identity_8007", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConsole script for satel_integra."}]}, {"id": "identity_2797", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nInstance depends on the API version:\n\n           * 2018-02-01-preview: :class:`BuildTasksOperations<azure.mgmt.containerregistry.v2018_02_01_preview.operations.BuildTasksOperations>`"}]}, {"id": "identity_4011", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nApply a two-qubit unitary matrix.\n\n        Args:\n            gate (matrix_like): a the two-qubit gate matrix\n            qubit0 (int): gate qubit-0\n            qubit1 (int): gate qubit-1"}]}, {"id": "identity_1363", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nAugment a sample shape to broadcast batch dimensions.\n\n  Computes an augmented sample shape, so that any batch dimensions not\n  part of the distribution `partial_batch_dist` are treated as identical\n  distributions.\n\n  # partial_batch_dist.batch_shape  = [      7]\n  # full_sample_and_batch_shape     = [3, 4, 7]\n  # => return an augmented sample shape of [3, 4] so that\n  #    partial_batch_dist.sample(augmented_sample_shape) has combined\n  #    sample and batch shape of [3, 4, 7].\n\n  Args:\n    partial_batch_dist: `tfd.Distribution` instance with batch shape a\n      prefix of `full_sample_and_batch_shape`.\n    full_sample_and_batch_shape: a Tensor or Tensor-like shape.\n    validate_args: if True, check for shape errors at runtime.\n  Returns:\n    augmented_sample_shape: sample shape such that\n      `partial_batch_dist.sample(augmented_sample_shape)` has combined\n      sample and batch shape of `full_sample_and_batch_shape`.\n\n  Raises:\n    ValueError: if `partial_batch_dist.batch_shape` has more dimensions than\n      `full_sample_and_batch_shape`.\n    NotImplementedError: if broadcasting would be required to make\n      `partial_batch_dist.batch_shape` into a prefix of\n      `full_sample_and_batch_shape` ."}]}, {"id": "identity_4045", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSelect the best remaining hardware qubit for the next program qubit."}]}, {"id": "identity_6118", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConstruct based on a ``cryptography`` *crypto_cert*.\n\n        :param crypto_key: A ``cryptography`` X.509 certificate.\n        :type crypto_key: ``cryptography.x509.Certificate``\n\n        :rtype: X509\n\n        .. versionadded:: 17.1.0"}]}, {"id": "identity_5347", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nEnsure all directories are created for a given target file."}]}, {"id": "identity_231", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRun a query for entities.\n\n        .. seealso::\n            https://cloud.google.com/datastore/docs/reference/rest/v1/projects/runQuery\n\n        :param body: the body of the query request.\n        :type body: dict\n        :return: the batch of query results.\n        :rtype: dict"}]}, {"id": "identity_4705", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns the names of all positional arguments to the given function."}]}, {"id": "identity_5893", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nadd dependencies created by from-imports"}]}, {"id": "identity_9242", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSkip N batches in the training."}]}, {"id": "identity_862", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPerform perspective transform of the given PIL Image.\n\n    Args:\n        img (PIL Image): Image to be transformed.\n        coeffs (tuple) : 8-tuple (a, b, c, d, e, f, g, h) which contains the coefficients.\n                            for a perspective transform.\n        interpolation: Default- Image.BICUBIC\n    Returns:\n        PIL Image:  Perspectively transformed Image."}]}, {"id": "identity_9422", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturns a list of segmentation masks each of the same dimension as the input one,\n    but where they each have exactly one segment in them and all other samples in them\n    are zeroed.\n\n    Only bothers to return segments that are larger in total area than `threshold * mask.size`."}]}, {"id": "identity_6594", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nDrop a node from the network\n\n        :param node: node to drop\n        :type node: Node"}]}, {"id": "identity_7235", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWrite the data encoding the QueryResponsePayload object to a stream.\n\n        Args:\n            output_buffer (Stream): A data stream in which to encode object\n                data, supporting a write method; usually a BytearrayStream\n                object.\n            kmip_version (KMIPVersion): An enumeration defining the KMIP\n                version with which the object will be encoded. Optional,\n                defaults to KMIP 1.0."}]}, {"id": "identity_7935", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nLoad crs object from sr-org code, via spatialreference.org.\n    Parses based on the proj4 representation.\n\n    Arguments:\n\n    - *code*: The SR-ORG code as an integer.\n\n    Returns:\n\n    - A CS instance of the indicated type."}]}, {"id": "identity_2850", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet a site's publish profile as a string\n\n        webspace_name:\n            The name of the webspace.\n        website_name:\n            The name of the website."}]}, {"id": "identity_6249", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nParse gene_sets.gmt(gene set database) file or download from enrichr server.\n\n    :param gmt: the gene_sets.gmt file of GSEA input or an enrichr library name.\n                checkout full enrichr library name here: http://amp.pharm.mssm.edu/Enrichr/#stats\n\n    :param min_size: Minimum allowed number of genes from gene set also the data set. Default: 3.\n    :param max_size: Maximum allowed number of genes from gene set also the data set. Default: 5000.\n    :param gene_list: Used for filtering gene set. Only used this argument for :func:`call` method.\n    :return: Return a new filtered gene set database dictionary.\n\n    **DO NOT** filter gene sets, when use :func:`replot`. Because ``GSEA`` Desktop have already\n    done this for you."}]}, {"id": "identity_8100", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRecursive helper for walk."}]}, {"id": "identity_4118", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nr\"\"\"Generates Y-only correction DRAG `SamplePulse` for standard nonlinear oscillator (SNO) [1].\n\n    Centered at `duration/2` and zeroed at `t=-1` to prevent large initial discontinuity.\n\n    Applies `left` sampling strategy to generate discrete pulse from continuous function.\n\n    [1] Gambetta, J. M., Motzoi, F., Merkel, S. T. & Wilhelm, F. K.\n        Analytic control methods for high-fidelity unitary operations\n        in a weakly nonlinear oscillator. Phys. Rev. A 83, 012308 (2011).\n\n\n    Args:\n        duration: Duration of pulse. Must be greater than zero.\n        amp: Pulse amplitude at `center`.\n        sigma: Width (standard deviation) of pulse.\n        beta: Y correction amplitude. For the SNO this is $\\beta=-\\frac{\\lambda_1^2}{4\\Delta_2}$.\n            Where $\\lambds_1$ is the relative coupling strength between the first excited and second\n            excited states and $\\Delta_2$ is the detuning between the resepective excited states.\n        name: Name of pulse."}]}, {"id": "identity_7282", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRuns HTTP GET request to retrieve the list of experiments."}]}, {"id": "identity_1451", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nComputes log(sum(x**2))."}]}, {"id": "identity_8476", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nGet all logical interfaces for a thing type.\n        Parameters:\n          - thingTypeId (string)\n          - draft (boolean)\n        Returns:\n            - list of logical interface ids\n            - HTTP response object\n        Throws APIException on failure."}]}, {"id": "identity_5379", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSearch for time information in the string"}]}, {"id": "identity_1537", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nApplies the L-BFGS algorithm to minimize a differentiable function.\n\n  Performs unconstrained minimization of a differentiable function using the\n  L-BFGS scheme. See [Nocedal and Wright(2006)][1] for details of the algorithm.\n\n  ### Usage:\n\n  The following example demonstrates the L-BFGS optimizer attempting to find the\n  minimum for a simple high-dimensional quadratic objective function.\n\n  ```python\n    # A high-dimensional quadratic bowl.\n    ndims = 60\n    minimum = np.ones([ndims], dtype='float64')\n    scales = np.arange(ndims, dtype='float64') + 1.0\n\n    # The objective function and the gradient.\n    def quadratic(x):\n      value = tf.reduce_sum(scales * (x - minimum) ** 2)\n      return value, tf.gradients(value, x)[0]\n\n    start = np.arange(ndims, 0, -1, dtype='float64')\n    optim_results = tfp.optimizer.lbfgs_minimize(\n        quadratic, initial_position=start, num_correction_pairs=10,\n        tolerance=1e-8)\n\n    with tf.Session() as session:\n      results = session.run(optim_results)\n      # Check that the search converged\n      assert(results.converged)\n      # Check that the argmin is close to the actual value.\n      np.testing.assert_allclose(results.position, minimum)\n  ```\n\n  ### References:\n\n  [1] Jorge Nocedal, Stephen Wright. Numerical Optimization. Springer Series\n      in Operations Research. pp 176-180. 2006\n\n  http://pages.mtu.edu/~struther/Courses/OLD/Sp2013/5630/Jorge_Nocedal_Numerical_optimization_267490.pdf\n\n  Args:\n    value_and_gradients_function:  A Python callable that accepts a point as a\n      real `Tensor` and returns a tuple of `Tensor`s of real dtype containing\n      the value of the function and its gradient at that point. The function\n      to be minimized. The input is of shape `[..., n]`, where `n` is the size\n      of the domain of input points, and all others are batching dimensions.\n      The first component of the return value is a real `Tensor` of matching\n      shape `[...]`. The second component (the gradient) is also of shape\n      `[..., n]` like the input value to the function.\n    initial_position: Real `Tensor` of shape `[..., n]`. The starting point, or\n      points when using batching dimensions, of the search procedure. At these\n      points the function value and the gradient norm should be finite.\n    num_correction_pairs: Positive integer. Specifies the maximum number of\n      (position_delta, gradient_delta) correction pairs to keep as implicit\n      approximation of the Hessian matrix.\n    tolerance: Scalar `Tensor` of real dtype. Specifies the gradient tolerance\n      for the procedure. If the supremum norm of the gradient vector is below\n      this number, the algorithm is stopped.\n    x_tolerance: Scalar `Tensor` of real dtype. If the absolute change in the\n      position between one iteration and the next is smaller than this number,\n      the algorithm is stopped.\n    f_relative_tolerance: Scalar `Tensor` of real dtype. If the relative change\n      in the objective value between one iteration and the next is smaller\n      than this value, the algorithm is stopped.\n    initial_inverse_hessian_estimate: None. Option currently not supported.\n    max_iterations: Scalar positive int32 `Tensor`. The maximum number of\n      iterations for L-BFGS updates.\n    parallel_iterations: Positive integer. The number of iterations allowed to\n      run in parallel.\n    stopping_condition: (Optional) A Python function that takes as input two\n      Boolean tensors of shape `[...]`, and returns a Boolean scalar tensor.\n      The input tensors are `converged` and `failed`, indicating the current\n      status of each respective batch member; the return value states whether\n      the algorithm should stop. The default is tfp.optimizer.converged_all\n      which only stops when all batch members have either converged or failed.\n      An alternative is tfp.optimizer.converged_any which stops as soon as one\n      batch member has converged, or when all have failed.\n    name: (Optional) Python str. The name prefixed to the ops created by this\n      function. If not supplied, the default name 'minimize' is used.\n\n  Returns:\n    optimizer_results: A namedtuple containing the following items:\n      converged: Scalar boolean tensor indicating whether the minimum was\n        found within tolerance.\n      failed:  Scalar boolean tensor indicating whether a line search\n        step failed to find a suitable step size satisfying Wolfe\n        conditions. In the absence of any constraints on the\n        number of objective evaluations permitted, this value will\n        be the complement of `converged`. However, if there is\n        a constraint and the search stopped due to available\n        evaluations being exhausted, both `failed` and `converged`\n        will be simultaneously False.\n      num_objective_evaluations: The total number of objective\n        evaluations performed.\n      position: A tensor containing the last argument value found\n        during the search. If the search converged, then\n        this value is the argmin of the objective function.\n      objective_value: A tensor containing the value of the objective\n        function at the `position`. If the search converged, then this is\n        the (local) minimum of the objective function.\n      objective_gradient: A tensor containing the gradient of the objective\n        function at the `position`. If the search converged the\n        max-norm of this tensor should be below the tolerance.\n      position_deltas: A tensor encoding information about the latest\n        changes in `position` during the algorithm execution.\n      gradient_deltas: A tensor encoding information about the latest\n        changes in `objective_gradient` during the algorithm execution."}]}, {"id": "identity_4600", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nReturn dictionary of transformed results, with keys being output names.\n        Returns None if execution result isn't a success.\n\n        Reconstructs the pipeline context to materialize values."}]}, {"id": "identity_4970", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nFetch the issues\n\n        :param category: the category of items to fetch\n        :param kwargs: backend arguments\n\n        :returns: a generator of items"}]}, {"id": "identity_9817", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nConvert Cnf object ot Dimacs cnf string\n        \n        cnf: Cnf object\n        \n        In the converted Cnf there will be only numbers for\n        variable names. The conversion guarantees that the\n        variables will be numbered alphabetically."}]}, {"id": "identity_5338", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCopy a single file or a directory by adding a task into queue"}]}, {"id": "identity_1165", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRuns annealed importance sampling (AIS) to estimate normalizing constants.\n\n  This function uses an MCMC transition operator (e.g., Hamiltonian Monte Carlo)\n  to sample from a series of distributions that slowly interpolates between\n  an initial \"proposal\" distribution:\n\n  `exp(proposal_log_prob_fn(x) - proposal_log_normalizer)`\n\n  and the target distribution:\n\n  `exp(target_log_prob_fn(x) - target_log_normalizer)`,\n\n  accumulating importance weights along the way. The product of these\n  importance weights gives an unbiased estimate of the ratio of the\n  normalizing constants of the initial distribution and the target\n  distribution:\n\n  `E[exp(ais_weights)] = exp(target_log_normalizer - proposal_log_normalizer)`.\n\n  Note: When running in graph mode, `proposal_log_prob_fn` and\n  `target_log_prob_fn` are called exactly three times (although this may be\n  reduced to two times in the future).\n\n  Args:\n    num_steps: Integer number of Markov chain updates to run. More\n      iterations means more expense, but smoother annealing between q\n      and p, which in turn means exponentially lower variance for the\n      normalizing constant estimator.\n    proposal_log_prob_fn: Python callable that returns the log density of the\n      initial distribution.\n    target_log_prob_fn: Python callable which takes an argument like\n      `current_state` (or `*current_state` if it's a list) and returns its\n      (possibly unnormalized) log-density under the target distribution.\n    current_state: `Tensor` or Python `list` of `Tensor`s representing the\n      current state(s) of the Markov chain(s). The first `r` dimensions index\n      independent chains, `r = tf.rank(target_log_prob_fn(*current_state))`.\n    make_kernel_fn: Python `callable` which returns a `TransitionKernel`-like\n      object. Must take one argument representing the `TransitionKernel`'s\n      `target_log_prob_fn`. The `target_log_prob_fn` argument represents the\n      `TransitionKernel`'s target log distribution.  Note:\n      `sample_annealed_importance_chain` creates a new `target_log_prob_fn`\n      which is an interpolation between the supplied `target_log_prob_fn` and\n      `proposal_log_prob_fn`; it is this interpolated function which is used as\n      an argument to `make_kernel_fn`.\n    parallel_iterations: The number of iterations allowed to run in parallel.\n        It must be a positive integer. See `tf.while_loop` for more details.\n    name: Python `str` name prefixed to Ops created by this function.\n      Default value: `None` (i.e., \"sample_annealed_importance_chain\").\n\n  Returns:\n    next_state: `Tensor` or Python list of `Tensor`s representing the\n      state(s) of the Markov chain(s) at the final iteration. Has same shape as\n      input `current_state`.\n    ais_weights: Tensor with the estimated weight(s). Has shape matching\n      `target_log_prob_fn(current_state)`.\n    kernel_results: `collections.namedtuple` of internal calculations used to\n      advance the chain.\n\n  #### Examples\n\n  ##### Estimate the normalizing constant of a log-gamma distribution.\n\n  ```python\n  tfd = tfp.distributions\n\n  # Run 100 AIS chains in parallel\n  num_chains = 100\n  dims = 20\n  dtype = np.float32\n\n  proposal = tfd.MultivatiateNormalDiag(\n     loc=tf.zeros([dims], dtype=dtype))\n\n  target = tfd.TransformedDistribution(\n    distribution=tfd.Gamma(concentration=dtype(2),\n                           rate=dtype(3)),\n    bijector=tfp.bijectors.Invert(tfp.bijectors.Exp()),\n    event_shape=[dims])\n\n  chains_state, ais_weights, kernels_results = (\n      tfp.mcmc.sample_annealed_importance_chain(\n          num_steps=1000,\n          proposal_log_prob_fn=proposal.log_prob,\n          target_log_prob_fn=target.log_prob,\n          current_state=proposal.sample(num_chains),\n          make_kernel_fn=lambda tlp_fn: tfp.mcmc.HamiltonianMonteCarlo(\n            target_log_prob_fn=tlp_fn,\n            step_size=0.2,\n            num_leapfrog_steps=2)))\n\n  log_estimated_normalizer = (tf.reduce_logsumexp(ais_weights)\n                              - np.log(num_chains))\n  log_true_normalizer = tf.lgamma(2.) - 2. * tf.log(3.)\n  ```\n\n  ##### Estimate marginal likelihood of a Bayesian regression model.\n\n  ```python\n  tfd = tfp.distributions\n\n  def make_prior(dims, dtype):\n    return tfd.MultivariateNormalDiag(\n        loc=tf.zeros(dims, dtype))\n\n  def make_likelihood(weights, x):\n    return tfd.MultivariateNormalDiag(\n        loc=tf.tensordot(weights, x, axes=[[0], [-1]]))\n\n  # Run 100 AIS chains in parallel\n  num_chains = 100\n  dims = 10\n  dtype = np.float32\n\n  # Make training data.\n  x = np.random.randn(num_chains, dims).astype(dtype)\n  true_weights = np.random.randn(dims).astype(dtype)\n  y = np.dot(x, true_weights) + np.random.randn(num_chains)\n\n  # Setup model.\n  prior = make_prior(dims, dtype)\n  def target_log_prob_fn(weights):\n    return prior.log_prob(weights) + make_likelihood(weights, x).log_prob(y)\n\n  proposal = tfd.MultivariateNormalDiag(\n      loc=tf.zeros(dims, dtype))\n\n  weight_samples, ais_weights, kernel_results = (\n      tfp.mcmc.sample_annealed_importance_chain(\n        num_steps=1000,\n        proposal_log_prob_fn=proposal.log_prob,\n        target_log_prob_fn=target_log_prob_fn\n        current_state=tf.zeros([num_chains, dims], dtype),\n        make_kernel_fn=lambda tlp_fn: tfp.mcmc.HamiltonianMonteCarlo(\n          target_log_prob_fn=tlp_fn,\n          step_size=0.1,\n          num_leapfrog_steps=2)))\n  log_normalizer_estimate = (tf.reduce_logsumexp(ais_weights)\n                             - np.log(num_chains))\n  ```"}]}, {"id": "identity_2360", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nRetrieve the index in this metric's threshold list at which the given threshold is located.\n\n        :param threshold: Find the index of this input threshold.\n        :returns: the index\n        :raises ValueError: if no such index can be found."}]}, {"id": "identity_3372", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nPhase vocoder.  Given an STFT matrix D, speed up by a factor of `rate`\n\n    Based on the implementation provided by [1]_.\n\n    .. [1] Ellis, D. P. W. \"A phase vocoder in Matlab.\"\n        Columbia University, 2002.\n        http://www.ee.columbia.edu/~dpwe/resources/matlab/pvoc/\n\n    Examples\n    --------\n    >>> # Play at double speed\n    >>> y, sr   = librosa.load(librosa.util.example_audio_file())\n    >>> D       = librosa.stft(y, n_fft=2048, hop_length=512)\n    >>> D_fast  = librosa.phase_vocoder(D, 2.0, hop_length=512)\n    >>> y_fast  = librosa.istft(D_fast, hop_length=512)\n\n    >>> # Or play at 1/3 speed\n    >>> y, sr   = librosa.load(librosa.util.example_audio_file())\n    >>> D       = librosa.stft(y, n_fft=2048, hop_length=512)\n    >>> D_slow  = librosa.phase_vocoder(D, 1./3, hop_length=512)\n    >>> y_slow  = librosa.istft(D_slow, hop_length=512)\n\n    Parameters\n    ----------\n    D : np.ndarray [shape=(d, t), dtype=complex]\n        STFT matrix\n\n    rate :  float > 0 [scalar]\n        Speed-up factor: `rate > 1` is faster, `rate < 1` is slower.\n\n    hop_length : int > 0 [scalar] or None\n        The number of samples between successive columns of `D`.\n\n        If None, defaults to `n_fft/4 = (D.shape[0]-1)/2`\n\n    Returns\n    -------\n    D_stretched : np.ndarray [shape=(d, t / rate), dtype=complex]\n        time-stretched STFT"}]}, {"id": "identity_8729", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nWrites given line to given output file.\n    See :func:`encode_output` for details."}]}, {"id": "identity_3954", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nCombines self and another_layout into an \"edge map\".\n\n        For example::\n\n              self       another_layout  resulting edge map\n           qr_1 -> 0        0 <- q_2         qr_1 -> q_2\n           qr_2 -> 2        2 <- q_1         qr_2 -> q_1\n           qr_3 -> 3        3 <- q_0         qr_3 -> q_0\n\n        The edge map is used to compose dags via, for example, compose_back.\n\n        Args:\n            another_layout (Layout): The other layout to combine.\n        Returns:\n            dict: A \"edge map\".\n        Raises:\n            LayoutError: another_layout can be bigger than self, but not smaller. Otherwise, raises."}]}, {"id": "identity_5615", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nreturn the visit name for the mixed class. When calling 'accept', the\n        method <'visit_' + name returned by this method> will be called on the\n        visitor"}]}, {"id": "identity_195", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nSleeps until all the processors are done."}]}, {"id": "identity_9223", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nTrain the model in multi-GPU environment."}]}, {"id": "identity_7719", "conversation": [{"role": "user", "content": "Please generate code based on the following doc:\nUtility function to convert (r,g,b) triples to hex.\n    http://ageo.co/1CFxXpO\n    Args:\n      rgb (tuple): A sequence of RGB values in the\n        range 0-255 or 0-1.\n    Returns:\n      str: The hex code for the colour."}]}]